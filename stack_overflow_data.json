[
    {
        "question_title": "Python - Create files from Strings\n\n\n\n        Ask Question",
        "question_body": "I need to read my file, grab the first part of a string (up to the first number), make a new file with that as the name. Then put all the other lines matching that String into the matching file. Example:\nABC1\nABC2\nABC3\nCBA1\nCBA2\nCBA3\nSo it should read the lines, get the \"ABC\" from line one, make a file name \"ABC\" and then put all the ABC rows in the new file. then grab \"CBA\" make a new file and put all the CBA rows in the CBA File.\nPlease help!! I am so lost and confused.\nI am learning python and have no idea how to start.",
        "tags": [
            "python",
            "python"
        ],
        "answers": [
            "I need to read my file, grab the first part of a string (up to the first number), make a new file with that as the name. Then put all the other lines matching that String into the matching file. Example:\nABC1\nABC2\nABC3\nCBA1\nCBA2\nCBA3\nSo it should read the lines, get the \"ABC\" from line one, make a file name \"ABC\" and then put all the ABC rows in the new file. then grab \"CBA\" make a new file and put all the CBA rows in the CBA File.\nPlease help!! I am so lost and confused.\nI am learning python and have no idea how to start."
        ]
    },
    {
        "question_title": "Display output from Vertex AI Agent builder\n\n\n\n        Ask Question",
        "question_body": "I've used Agent Builder to create a conversational agent and have integrated with Slack. The agent works perfectly in my Slack channel but does not display the final output or recommendation.\nWhat step am I missing?\nI have tried\n\nmanually adding the generated output in the examples I have created but to no avail.\nwritten an explicit instruction to display the output\nreinstalled the app several times in the Slack workspace after the above changes",
        "tags": [
            "vertex-ai-search",
            "vertex-ai-search"
        ],
        "answers": [
            "I've used Agent Builder to create a conversational agent and have integrated with Slack. The agent works perfectly in my Slack channel but does not display the final output or recommendation.\nWhat step am I missing?\nI have tried\n\nmanually adding the generated output in the examples I have created but to no avail.\nwritten an explicit instruction to display the output\nreinstalled the app several times in the Slack workspace after the above changes"
        ]
    },
    {
        "question_title": "How to pick an file from google drive picker and make it publicly viwable by using Oauth2\n\n\n\n        Ask Question",
        "question_body": "Problem Statement -\nI have to open a google drive picker to let user select the file, then I am storing only embed link  at database.\nAt view I am showing user the embedded view of that file image, now the problem is\nif image is publc or open to anyone then no problem, it shows view on all third party as well icognito\nwhen user selects any non public or private image, it only shows view in same browser where, user email is logged in\nSolution I am expecting\neither\n\nRestrict user to select only publicly viewable images\nmodify file permissions when user selects the file\n\nerror I am getting is\nTypeError: gapi.auth.getToken() is null as oauth window is not opening\nconst handleOpenPicker = async () => {\n    await loadGoogleApi();\n\n    const authInstance = gapi.auth2.getAuthInstance();\n    if (!authInstance.isSignedIn.get()) {\n      await authInstance.signIn();\n    }\n\n    const accessToken = gapi.auth.getToken().access_token;\n    if (!accessToken) {\n      console.error(\"Access token is not available\");\n      return;\n    }\n\n    const openPicker = () => {\n      // @ts-ignore\n      const google = window.google;\n      const picker = new google.picker.PickerBuilder()\n        .setAppId(clientId)\n        .setDeveloperKey(developerKey)\n        .setOAuthToken(accessToken)\n        .addView(google.picker.ViewId.DOCS_IMAGES_AND_VIDEOS)\n        .setCallback(async (data: any) => {\n          if (data.action === \"picked\" && data.docs && data.docs.length > 0) {\n            const doc = data.docs[0];\n            if (allowedDriveMediaTypes.includes(doc.mimeType)) {\n              try {\n                await makeFilePublic(doc.id);\n                setLink(doc.url);\n                handleSlideImageUpdate(index, undefined, doc.url);\n                setOpenCloseState(false);\n              } catch (error) {\n                console.error(\"Error accessing file:\", error);\n              }\n            } else {\n              console.log(\"Unsupported file type\");\n            }\n          } else if (data.action === \"cancel\") {\n            console.log(\"User clicked cancel/close button\");\n          }\n        })\n        .build();\n\n      picker.setVisible(true);\n    };\n\n    openPicker();\n  };\n\n// functoin to modify file permissions\n  const makeFilePublic = async (fileId: string) => {\n    try {\n      await gapi.client.drive.permissions.create({\n        fileId: fileId,\n        resource: {\n          role: \"reader\",\n          type: \"anyone\",\n        },\n      });\n      console.log(\"File made public\");\n    } catch (error) {\n      console.error(\"Error making file public:\", error);\n    }\n  };\n\nexport const loadGoogleApi = (): Promise<void> => {\n  return new Promise((resolve, reject) => {\n    if (typeof gapi !== \"undefined\") {\n      resolve();\n    } else {\n      const script = document.createElement(\"script\");\n      script.src = \"https://apis.google.com/js/api.js\";\n      script.onload = () => {\n        gapi.load(\"client:auth2\", async () => {\n          try {\n            await gapi.client.init({\n              apiKey: process.env.NEXT_PUBLIC_GCP_DEVELOPER_KEY,\n              clientId: process.env.NEXT_PUBLIC_GCP_OAUTH_CLIENT_ID,\n              discoveryDocs: [\"https://www.googleapis.com/discovery/v1/apis/drive/v3/rest\"],\n              scope: \"https://www.googleapis.com/auth/drive.file\",\n            });\n\n            // Ensure user signed in\n            const authInstance = gapi.auth2.getAuthInstance();\n            if (!authInstance.isSignedIn.get()) {\n              await authInstance.signIn();\n            }\n\n            resolve();\n          } catch (error) {\n            reject(error);\n          }\n        });\n      };\n      script.onerror = (error) => reject(error);\n      document.body.appendChild(script);\n    }\n  });\n};",
        "tags": [
            "typescript",
            "next.js",
            "google-drive-api",
            "google-oauth",
            "google-drive-picker",
            "typescript",
            "next.js",
            "google-drive-api",
            "google-oauth",
            "google-drive-picker"
        ],
        "answers": [
            "Problem Statement -\nI have to open a google drive picker to let user select the file, then I am storing only embed link  at database.\nAt view I am showing user the embedded view of that file image, now the problem is\nif image is publc or open to anyone then no problem, it shows view on all third party as well icognito\nwhen user selects any non public or private image, it only shows view in same browser where, user email is logged in\nSolution I am expecting\neither\n\nRestrict user to select only publicly viewable images\nmodify file permissions when user selects the file\n\nerror I am getting is\nTypeError: gapi.auth.getToken() is null as oauth window is not opening\nconst handleOpenPicker = async () => {\n    await loadGoogleApi();\n\n    const authInstance = gapi.auth2.getAuthInstance();\n    if (!authInstance.isSignedIn.get()) {\n      await authInstance.signIn();\n    }\n\n    const accessToken = gapi.auth.getToken().access_token;\n    if (!accessToken) {\n      console.error(\"Access token is not available\");\n      return;\n    }\n\n    const openPicker = () => {\n      // @ts-ignore\n      const google = window.google;\n      const picker = new google.picker.PickerBuilder()\n        .setAppId(clientId)\n        .setDeveloperKey(developerKey)\n        .setOAuthToken(accessToken)\n        .addView(google.picker.ViewId.DOCS_IMAGES_AND_VIDEOS)\n        .setCallback(async (data: any) => {\n          if (data.action === \"picked\" && data.docs && data.docs.length > 0) {\n            const doc = data.docs[0];\n            if (allowedDriveMediaTypes.includes(doc.mimeType)) {\n              try {\n                await makeFilePublic(doc.id);\n                setLink(doc.url);\n                handleSlideImageUpdate(index, undefined, doc.url);\n                setOpenCloseState(false);\n              } catch (error) {\n                console.error(\"Error accessing file:\", error);\n              }\n            } else {\n              console.log(\"Unsupported file type\");\n            }\n          } else if (data.action === \"cancel\") {\n            console.log(\"User clicked cancel/close button\");\n          }\n        })\n        .build();\n\n      picker.setVisible(true);\n    };\n\n    openPicker();\n  };\n\n// functoin to modify file permissions\n  const makeFilePublic = async (fileId: string) => {\n    try {\n      await gapi.client.drive.permissions.create({\n        fileId: fileId,\n        resource: {\n          role: \"reader\",\n          type: \"anyone\",\n        },\n      });\n      console.log(\"File made public\");\n    } catch (error) {\n      console.error(\"Error making file public:\", error);\n    }\n  };\n\nexport const loadGoogleApi = (): Promise<void> => {\n  return new Promise((resolve, reject) => {\n    if (typeof gapi !== \"undefined\") {\n      resolve();\n    } else {\n      const script = document.createElement(\"script\");\n      script.src = \"https://apis.google.com/js/api.js\";\n      script.onload = () => {\n        gapi.load(\"client:auth2\", async () => {\n          try {\n            await gapi.client.init({\n              apiKey: process.env.NEXT_PUBLIC_GCP_DEVELOPER_KEY,\n              clientId: process.env.NEXT_PUBLIC_GCP_OAUTH_CLIENT_ID,\n              discoveryDocs: [\"https://www.googleapis.com/discovery/v1/apis/drive/v3/rest\"],\n              scope: \"https://www.googleapis.com/auth/drive.file\",\n            });\n\n            // Ensure user signed in\n            const authInstance = gapi.auth2.getAuthInstance();\n            if (!authInstance.isSignedIn.get()) {\n              await authInstance.signIn();\n            }\n\n            resolve();\n          } catch (error) {\n            reject(error);\n          }\n        });\n      };\n      script.onerror = (error) => reject(error);\n      document.body.appendChild(script);\n    }\n  });\n};"
        ]
    },
    {
        "question_title": "Display Issues when Using Multiple SQLite Tables from a Single Database in Delphi\n\n\n\n        Ask Question",
        "question_body": "I am developing an application that uses multiple SQLite tables from a single database. These tables are not related to each other in any way. I have a TFDConnection for the database, TDBGrid and TDBNavigator controls for each table, TFDQuery and TDataSource for each table.\nThe TFDQuery for each table is: SELECT * FROM MRSales and SELECT * FROM MRCogs\nThe following is the main forms create code that contains the code to open the tables.\nprocedure TForm1.MainFormCreate(Sender: TObject);\nbegin\n    left:=(Screen.Width-Width) div 2;\n    top:=(Screen.Height-Height) div 2;\n    MrsalesTable.open;\n    MrcogsTable.open;\n    LoadCombos;\nend;\n\nWhen I run the application I get records to display in DBGrid1 from the first table MrSalesTable, but none display in DBGrid2 from the second table MrcogsTable. The DBGrid2 and DBNavigator2 appear to recognize the table and act as if there are records in the table (there are two actual records in the table) but nothing shows up.\nEach DBGrid has the OnColExit event set to perform some computations and save the results to the table. This event code seems to be working just fine when operating on the first DBGrid1. Below is the code for DBGrid1. DBGrid2 is identical but DBGrid1 is replaced with DBGrid2.\nprocedure TForm1.Grid1OnColExit(Sender: TObject);\nvar\n    i,ccode : integer;\n    amt1,amt2 : currency;\nbegin\n    // zero the variables and retrive the number of months our P&L has\n    //amt1:=0;\n    //amt2:=0;\n    val(cbModelMonths.text,i,ccode);\n\n    // check if the val() function had an error. If so, display a message\n    // and exit the function, otherwise continue on\n    if ccode <> 0 then\n    begin\n        MessageDlg('Error at Position: ' + IntToStr(ccode) +\n           ', i='+IntToStr(i),mtwarning,[mbok],0,mbok);\n        exit;\n    end;\n\n    // determine which column we are dealing with\n    case DBGrid1.SelectedIndex of\n        // this is the amount value column\n        2:  begin\n                if i < 12 then\n                    begin\n                        if DBGrid1.Fields[2].asCurrency > 0 then\n                            begin\n                                amt1:=DBGrid1.Fields[2].asCurrency;\n                                amt2:=(amt1 / i) * 12;\n                                DBGrid1.Fields[3].asCurrency:=amt2;\n                            end;\n                    end\n                else\n                    if DBGrid1.Fields[2].asCurrency > 0 then\n                        DBGrid1.Fields[3].asCurrency:=DBGrid1.Fields[3].asCurrency;\n            end;\n        // this is the adjustment value column\n        4:  begin\n                if DBGrid1.Fields[3].asCurrency > 0 then\n                    DBGrid1.Fields[5].AsCurrency:=DBGrid1.Fields[3].AsCurrency+\n                       DBGrid1.Fields[4].AsCurrency\n                else\n                    DBGrid1.Fields[5].AsCurrency:=0;\n            end;\n    end;\nend;\n\nThe rest of the applications setup is done via the object inspector and data explorer.",
        "tags": [
            "sqlite",
            "delphi",
            "sqlite",
            "delphi"
        ],
        "answers": [
            "I am developing an application that uses multiple SQLite tables from a single database. These tables are not related to each other in any way. I have a TFDConnection for the database, TDBGrid and TDBNavigator controls for each table, TFDQuery and TDataSource for each table.\nThe TFDQuery for each table is: SELECT * FROM MRSales and SELECT * FROM MRCogs\nThe following is the main forms create code that contains the code to open the tables.\nprocedure TForm1.MainFormCreate(Sender: TObject);\nbegin\n    left:=(Screen.Width-Width) div 2;\n    top:=(Screen.Height-Height) div 2;\n    MrsalesTable.open;\n    MrcogsTable.open;\n    LoadCombos;\nend;\n\nWhen I run the application I get records to display in DBGrid1 from the first table MrSalesTable, but none display in DBGrid2 from the second table MrcogsTable. The DBGrid2 and DBNavigator2 appear to recognize the table and act as if there are records in the table (there are two actual records in the table) but nothing shows up.\nEach DBGrid has the OnColExit event set to perform some computations and save the results to the table. This event code seems to be working just fine when operating on the first DBGrid1. Below is the code for DBGrid1. DBGrid2 is identical but DBGrid1 is replaced with DBGrid2.\nprocedure TForm1.Grid1OnColExit(Sender: TObject);\nvar\n    i,ccode : integer;\n    amt1,amt2 : currency;\nbegin\n    // zero the variables and retrive the number of months our P&L has\n    //amt1:=0;\n    //amt2:=0;\n    val(cbModelMonths.text,i,ccode);\n\n    // check if the val() function had an error. If so, display a message\n    // and exit the function, otherwise continue on\n    if ccode <> 0 then\n    begin\n        MessageDlg('Error at Position: ' + IntToStr(ccode) +\n           ', i='+IntToStr(i),mtwarning,[mbok],0,mbok);\n        exit;\n    end;\n\n    // determine which column we are dealing with\n    case DBGrid1.SelectedIndex of\n        // this is the amount value column\n        2:  begin\n                if i < 12 then\n                    begin\n                        if DBGrid1.Fields[2].asCurrency > 0 then\n                            begin\n                                amt1:=DBGrid1.Fields[2].asCurrency;\n                                amt2:=(amt1 / i) * 12;\n                                DBGrid1.Fields[3].asCurrency:=amt2;\n                            end;\n                    end\n                else\n                    if DBGrid1.Fields[2].asCurrency > 0 then\n                        DBGrid1.Fields[3].asCurrency:=DBGrid1.Fields[3].asCurrency;\n            end;\n        // this is the adjustment value column\n        4:  begin\n                if DBGrid1.Fields[3].asCurrency > 0 then\n                    DBGrid1.Fields[5].AsCurrency:=DBGrid1.Fields[3].AsCurrency+\n                       DBGrid1.Fields[4].AsCurrency\n                else\n                    DBGrid1.Fields[5].AsCurrency:=0;\n            end;\n    end;\nend;\n\nThe rest of the applications setup is done via the object inspector and data explorer."
        ]
    },
    {
        "question_title": "Dynamic imports in Webpack\n\n\n\n        Ask Question",
        "question_body": "I have a webpack file (that borrows from this: https://github.com/webpack/webpack/issues/5493):\nimport type { Configuration } from 'webpack'\n\nconst config: Configuration = {\n    // other properties\n    plugins: [\n        // other plugins\n        webpackBarPlugin()\n        // other plugins\n    ].filter(Boolean)\n    // other properties\n}\n\nexport default config\n\nAnd a helper function to generate the plugin - the key is that I want the plugin to be dynamically imported.\nexport const webpackBarPlugin = () => {\n    if (process.env.NODE_ENV === 'development') {\n        import('webpackbar').then(module => {\n            const WebpackBar = module.default\n            return new WebpackBar()\n        })\n    }\n\n    return false\n}\n\nWhen hovering over the function name, it reads: () => boolean instead of what I would want: () => boolean | WebpackBarPlugin. Hence, when attempting this build, this does not work. I have tried all kinds of things to refactor this but can't seem to get plugin to return properly.",
        "tags": [
            "webpack",
            "webpack"
        ],
        "answers": [
            "I have a webpack file (that borrows from this: https://github.com/webpack/webpack/issues/5493):\nimport type { Configuration } from 'webpack'\n\nconst config: Configuration = {\n    // other properties\n    plugins: [\n        // other plugins\n        webpackBarPlugin()\n        // other plugins\n    ].filter(Boolean)\n    // other properties\n}\n\nexport default config\n\nAnd a helper function to generate the plugin - the key is that I want the plugin to be dynamically imported.\nexport const webpackBarPlugin = () => {\n    if (process.env.NODE_ENV === 'development') {\n        import('webpackbar').then(module => {\n            const WebpackBar = module.default\n            return new WebpackBar()\n        })\n    }\n\n    return false\n}\n\nWhen hovering over the function name, it reads: () => boolean instead of what I would want: () => boolean | WebpackBarPlugin. Hence, when attempting this build, this does not work. I have tried all kinds of things to refactor this but can't seem to get plugin to return properly."
        ]
    },
    {
        "question_title": "Read large binary file in chunks in Microsoft SQL Server\n\n\n\n        Ask Question",
        "question_body": "Is there any functionality that allows reading binary file in chunks?\nCurrenty I am using a following query to read binary files:\nSELECT image_data.BulkColumn FROM OPENROWSET(BULK 'C:\\bigfile', SINGLE_BLOB) as image_data\nWhen size of the file is about 3 GB, the query takes about 50 seconds to execute.\nWhen I am trying to extract a chunk from varbinary:\nSELECT SUBSTRING(image_data.BulkColumn, 1, 15) FROM OPENROWSET(BULK 'C:\\bigfile', SINGLE_BLOB) as image_data\nit takes about 28 seconds, no matter what the value of substring-offset is.\nAre there any other ways to make the file-to-sql gateway in a more effective way?",
        "tags": [
            "sql-server",
            "openrowset",
            "sql-server",
            "openrowset"
        ],
        "answers": [
            "Is there any functionality that allows reading binary file in chunks?\nCurrenty I am using a following query to read binary files:\nSELECT image_data.BulkColumn FROM OPENROWSET(BULK 'C:\\bigfile', SINGLE_BLOB) as image_data\nWhen size of the file is about 3 GB, the query takes about 50 seconds to execute.\nWhen I am trying to extract a chunk from varbinary:\nSELECT SUBSTRING(image_data.BulkColumn, 1, 15) FROM OPENROWSET(BULK 'C:\\bigfile', SINGLE_BLOB) as image_data\nit takes about 28 seconds, no matter what the value of substring-offset is.\nAre there any other ways to make the file-to-sql gateway in a more effective way?"
        ]
    },
    {
        "question_title": "Many lookups, aggregated dump, collapse query?\n\n\n\n        Ask Question",
        "question_body": "Let's say I have an index where my documents are cars.\nEach car some of the following attributes: make, model, color, production year, engine type, length, number of seats, etc.\nI have a list of models for a given brand.\nI want to retrieve the generic information about each model so I only need to pull one document for each model.\nExample: the model is a Camry. I want to know it's a sedan, 5 seats, 15 feet long, etc. I don't care about each individual camry's color, year, etc.\nHere is what I thought about doing:\n\nMultisearch: To run many lookups but still, it is not scalable\nMatch all query with a filter on Make and collapse on Model: Not compatible with paginated search and my index is too large\nAggregate on Model, sub-aggregate on the fields I am looking for, filter by Make. Is that too computationally intensive?\n\nIs there another option I didn't think of, or a workaround for the issues I am encountering?",
        "tags": [
            "elasticsearch",
            "opensearch",
            "elasticsearch",
            "opensearch"
        ],
        "answers": [
            "Let's say I have an index where my documents are cars.\nEach car some of the following attributes: make, model, color, production year, engine type, length, number of seats, etc.\nI have a list of models for a given brand.\nI want to retrieve the generic information about each model so I only need to pull one document for each model.\nExample: the model is a Camry. I want to know it's a sedan, 5 seats, 15 feet long, etc. I don't care about each individual camry's color, year, etc.\nHere is what I thought about doing:\n\nMultisearch: To run many lookups but still, it is not scalable\nMatch all query with a filter on Make and collapse on Model: Not compatible with paginated search and my index is too large\nAggregate on Model, sub-aggregate on the fields I am looking for, filter by Make. Is that too computationally intensive?\n\nIs there another option I didn't think of, or a workaround for the issues I am encountering?"
        ]
    },
    {
        "question_title": "DIV with position:absolute dragged by a subsequent object\n\n\n\n        Ask Question",
        "question_body": "Why is div1 being pushed from the top edge? It seems to follow div2 margin setting.\nI would expect div1 to behave independently of div2 (i.e. stick to the top). Is there any way to keep div1 at the top of the screen without using top:0.\n\n\n* {\n  margin: 0;\n  padding: 0;\n  border: 0;\n}\n\n.div1 {\n  margin: 0rem;\n  background: red;\n  position: absolute;\n}\n\n.div2 {\n  margin: 3rem;\n  background: grey;\n}\n<div class=\"div1\">div1</div>\n<div class=\"div2\">div2</div>\n\n\n\nScreenshot of the code above",
        "tags": [
            "css",
            "css"
        ],
        "answers": [
            "Why is div1 being pushed from the top edge? It seems to follow div2 margin setting.\nI would expect div1 to behave independently of div2 (i.e. stick to the top). Is there any way to keep div1 at the top of the screen without using top:0.\n\n\n* {\n  margin: 0;\n  padding: 0;\n  border: 0;\n}\n\n.div1 {\n  margin: 0rem;\n  background: red;\n  position: absolute;\n}\n\n.div2 {\n  margin: 3rem;\n  background: grey;\n}\n<div class=\"div1\">div1</div>\n<div class=\"div2\">div2</div>\n\n\n\nScreenshot of the code above"
        ]
    },
    {
        "question_title": "Flutter compiling takes all CPU/RAM\n\n\n\n        Ask Question",
        "question_body": "I'm trying to compile the default Flutter app in Visual Studio Code (latest version) on a Mac with the M1 chip (version: 14.2.1 (23C71), Sonoma).\nWhen I try to compile my Flutter app (Flutter version: 3.16.5) with just some dependencies in the pubspec.yaml (see below), if I run it on an IOS simulator (iPhone 15 Pro Max - iOS 17.4) it occupies all the CPU of the computer (it does it with even a physical device), while, when I compile it on an Android emulator, it occupies all the RAM.\nHere is the pubspec.yaml dependencies:\n  cupertino_icons: ^1.0.2\n  firebase_core: ^2.27.0\n  firebase_auth: ^4.17.8\n  flutter_riverpod: ^2.5.1\n  cloud_firestore: ^4.15.8\n  syncfusion_flutter_charts: ^25.2.4\n  lottie: ^3.1.1\n\nI also noticed that this happened only when I added just a few dependencies.\nOnce I tried contacting Firebase support, since I thought I was due to the Firebase dependencies. They informed me they didn't notice any issue with the app or the dependencies. Moreover, I face this issue with any other Flutter app, and for this reason, I suppose my machine causes the problem.\nIf I missed some useful information please let me know and I will update the question ASAP.",
        "tags": [
            "flutter",
            "flutter"
        ],
        "answers": [
            "I'm trying to compile the default Flutter app in Visual Studio Code (latest version) on a Mac with the M1 chip (version: 14.2.1 (23C71), Sonoma).\nWhen I try to compile my Flutter app (Flutter version: 3.16.5) with just some dependencies in the pubspec.yaml (see below), if I run it on an IOS simulator (iPhone 15 Pro Max - iOS 17.4) it occupies all the CPU of the computer (it does it with even a physical device), while, when I compile it on an Android emulator, it occupies all the RAM.\nHere is the pubspec.yaml dependencies:\n  cupertino_icons: ^1.0.2\n  firebase_core: ^2.27.0\n  firebase_auth: ^4.17.8\n  flutter_riverpod: ^2.5.1\n  cloud_firestore: ^4.15.8\n  syncfusion_flutter_charts: ^25.2.4\n  lottie: ^3.1.1\n\nI also noticed that this happened only when I added just a few dependencies.\nOnce I tried contacting Firebase support, since I thought I was due to the Firebase dependencies. They informed me they didn't notice any issue with the app or the dependencies. Moreover, I face this issue with any other Flutter app, and for this reason, I suppose my machine causes the problem.\nIf I missed some useful information please let me know and I will update the question ASAP."
        ]
    },
    {
        "question_title": "How to Efficiently Insert or Upsert a Single Column in PostgreSQL for Optimal Performance?\n\n\n\n        Ask Question",
        "question_body": "I’m seeking guidance on how to use PostgreSQL to update multiple rows in a specific column. I’m particularly interested in methods that offer optimal performance. Any help would be greatly appreciated\nI created a ref table here DBFiddle\nMy goal is to update the ‘status’ column of all records to ‘INACTIVE’. Currently, I’m working with a small table, but in a real-world scenario, I would need to apply this to approximately 10,000 records.\nI attempted to use a particular method (which I’ll detail below), but I was unable to get it to function correctly.\ninsert (id, status) values (...), (...) on conflict update \nand an example I was trying\nINSERT INTO questionnaires (id, status)\n        VALUES(190, 'ACTIVE'), (191, 'ACTIVE') ON CONFLICT (id)\n        DO\n        UPDATE\n        SET\n            status = EXCLUDED.status\n        WHERE\n            questionnaires.status <> EXCLUDED.status;\n\nI consistently encounter a ‘not-null violation’ error for the other columns. I’ve read online that the method I’m trying to use should be more optimized and\nperformance-friendly, allowing me to update all records at once instead of one by one. However, I’m struggling to implement it without errors.\nOne approach I’ve considered is to first select all the relevant records, then pass all the data, along with the updates I want to make, to the insert operation. This might help me avoid the null issue.\nHowever, I suspect there might be a more efficient way to accomplish this. Any suggestions or insights would be greatly appreciated.",
        "tags": [
            "sql",
            "postgresql",
            "sql",
            "postgresql"
        ],
        "answers": [
            "I’m seeking guidance on how to use PostgreSQL to update multiple rows in a specific column. I’m particularly interested in methods that offer optimal performance. Any help would be greatly appreciated\nI created a ref table here DBFiddle\nMy goal is to update the ‘status’ column of all records to ‘INACTIVE’. Currently, I’m working with a small table, but in a real-world scenario, I would need to apply this to approximately 10,000 records.\nI attempted to use a particular method (which I’ll detail below), but I was unable to get it to function correctly.\ninsert (id, status) values (...), (...) on conflict update \nand an example I was trying\nINSERT INTO questionnaires (id, status)\n        VALUES(190, 'ACTIVE'), (191, 'ACTIVE') ON CONFLICT (id)\n        DO\n        UPDATE\n        SET\n            status = EXCLUDED.status\n        WHERE\n            questionnaires.status <> EXCLUDED.status;\n\nI consistently encounter a ‘not-null violation’ error for the other columns. I’ve read online that the method I’m trying to use should be more optimized and\nperformance-friendly, allowing me to update all records at once instead of one by one. However, I’m struggling to implement it without errors.\nOne approach I’ve considered is to first select all the relevant records, then pass all the data, along with the updates I want to make, to the insert operation. This might help me avoid the null issue.\nHowever, I suspect there might be a more efficient way to accomplish this. Any suggestions or insights would be greatly appreciated."
        ]
    },
    {
        "question_title": "Azure App Service: Is it possible to know backend compute details for App service\n\n\n\n        Ask Question",
        "question_body": "Is there a way to know where the app service is deployed to (like the VM/Backend details), I wanted to prove : when an app service is deployed using non-premium pricing tier and Zone redundancy disabled, All the instances (in my case the instance count: 3) will go to same AZ.\nAny other inputs to prove this are most welcomed.\nRead through the documentation but no where it is explicitly stated that all the instances go to the same AZ but it is implied though.",
        "tags": [
            "azure",
            "azure-web-app-service",
            "azure",
            "azure-web-app-service"
        ],
        "answers": [
            "Is there a way to know where the app service is deployed to (like the VM/Backend details), I wanted to prove : when an app service is deployed using non-premium pricing tier and Zone redundancy disabled, All the instances (in my case the instance count: 3) will go to same AZ.\nAny other inputs to prove this are most welcomed.\nRead through the documentation but no where it is explicitly stated that all the instances go to the same AZ but it is implied though."
        ]
    },
    {
        "question_title": "XGBoost Time Series Diff Feature\n\n\n\n        Ask Question",
        "question_body": "I have a question, can someone help?\nLet's suppose I have day 1,2,3,4 and want to predict day 5:\nFeatures = Weekday, Diff\nTarget = Value\nWeekday: 1,2,3,4,5 | Diff: NaN,40,20,20,(?) | Value: 20,60,80,100,(?)\nWhen I train my model using diff() as feature, it really enhances the results. But what is the purpose of using it, if I can't use it to predict future steps?\nIs there a way I can use it as my input? Otherwise I don't see the purpose of using diff in my training\nI would be very glad if someone can explain me and give me some ideas to deal with it.\nI tried using the diff from last two days as an approximation to fill in day 5, but it really didn't help since my data has a lot of peaks and downs",
        "tags": [
            "python",
            "data-science",
            "data-analysis",
            "xgboost",
            "feature-engineering",
            "python",
            "data-science",
            "data-analysis",
            "xgboost",
            "feature-engineering"
        ],
        "answers": [
            "I have a question, can someone help?\nLet's suppose I have day 1,2,3,4 and want to predict day 5:\nFeatures = Weekday, Diff\nTarget = Value\nWeekday: 1,2,3,4,5 | Diff: NaN,40,20,20,(?) | Value: 20,60,80,100,(?)\nWhen I train my model using diff() as feature, it really enhances the results. But what is the purpose of using it, if I can't use it to predict future steps?\nIs there a way I can use it as my input? Otherwise I don't see the purpose of using diff in my training\nI would be very glad if someone can explain me and give me some ideas to deal with it.\nI tried using the diff from last two days as an approximation to fill in day 5, but it really didn't help since my data has a lot of peaks and downs"
        ]
    },
    {
        "question_title": "I'm building a dash app, and I'm having trouble managing the inputs from drop down menus on multiple different navbar tabs\n\n\n\n        Ask Question",
        "question_body": "I am new to dash, and building an app to visualize some data. Here's my problem. In my app, I have 3 navbar tabs to visualize data. Each tab corresponds to the level at which you can view the data, going from National view, a state view, and then a city view. Each view has drop down menus that correspond with how you can filter the data. The city view has 3, for the country, state and city. The State view has 2, and the country view has 1. The value of one drop down menu, is supposed to be input for the other. Eg, you can pick the states of a chosen country.\nCurrently, only the city view will work, and I get errors with the other 2 views.\nThis is the error I'm getting with the provincial and country view.\n\"A nonexistent object was used in an Input of a Dash callback. The id of this object is city-dropdown and the property is value.\"\nBelow is the relevant code. I'm hoping somebody can help me diagnose the issue, or suggest a more optimal way to do this. I am new to dash, and figuring this all out for the first time.\n@app.callback(Output('toggle-switches-content', 'children'),\n              [Input('url', 'pathname')])\ndef update_toggle_switches_content(pathname):\n    # The not working state view \n    if pathname == \"/provincial\":\n        return html.Div([\n            daq.ToggleSwitch(id='toggle-provincial', label=\"Real Time | Historical\",\n                             style={'display': 'inline-block', 'margin-right': '10px'}),\n\n            html.Div([\n                dcc.Dropdown(\n                    id='country-dropdown',\n                    options=[{'label': country, 'value': country}\n                        for country in unique_countries],\n                    value=None,  # Default value\n                    placeholder=\"Select a country\",\n                    style={'display': 'inline-block', 'margin-right': '10px',\n                        'width': '200px', 'height': '40px'}\n                ),\n                dcc.Dropdown(\n                    id='state-dropdown',\n                    value=None,  # Default value\n                    placeholder=\"Select a state\",\n                    style={'display': 'inline-block', 'margin-right': '10px',\n                           'width': '200px', 'height': '40px'}\n                ),\n            ], style={'display': 'inline-block'}),\n            html.Div(id='output'),\n            html.Div(id='graph-container', style={'margin-top': '20px'}),\n\n        ])\n    # The working city view \n    elif pathname == '/city':\n        return html.Div([\n            daq.ToggleSwitch(\n                id='toggle-provincial',\n                label=\"Real Time | Historical\",\n                style={'display': 'inline-block', 'margin-right': '10px'}\n            ),\n\n            html.Div([\n                dcc.Dropdown(\n                    id='country-dropdown',\n                    options=[{'label': country, 'value': country}\n                             for country in unique_countries],\n                    value=None,\n                    placeholder=\"Select a country\",\n                    style={'display': 'inline-block', 'margin-right': '10px',\n                           'width': '200px', 'height': '40px'}\n                ),\n                dcc.Dropdown(\n                    id='state-dropdown',\n                    value=None,\n                    placeholder=\"Select a state\",\n                    style={'display': 'inline-block', 'margin-right': '10px',\n                           'width': '200px', 'height': '40px'}\n                ),\n                dcc.Dropdown(\n                    id='city-dropdown',  # Add the city-dropdown here\n                    value=None,\n                    placeholder=\"Select a city\",\n                    style={'display': 'inline-block', 'margin-right': '10px',\n                           'width': '200px', 'height': '40px'}\n                ),\n            ], style={'display': 'inline-block'}),\n            html.Div(id='output'),\n            html.Div(id='graph-container', style={'margin-top': '20px'}),\n\n        ])  \n        # The  not working country view \n        else:\n        return html.Div([\n            daq.ToggleSwitch(id='toggle-provincial', label=\"Real Time | Historical\",\n                             style={'display': 'inline-block', 'margin-right': '10px'}),\n\n            dcc.Dropdown(\n                id='country-dropdown',\n                options=[{'label': country, 'value': country}\n                        for country in unique_countries],\n                value=None,  # Default value\n                style={'display': 'inline-block', 'margin-right': '10px',\n                       'width': '200px', 'height': '40px'}\n            ),\n            html.Div(id='output'),\n            html.Div(id='graph-container', style={'margin-top': '20px'}),\n\n        ]) \n\n\n\nRelevant call back functions \n\n\ndef update_graphs(df, city=None, province=None, country=None):\n    # Filter the DataFrame based on selected city, province, and country\n    filtered_df = df.copy()\n    if city:\n        filtered_df = filtered_df[filtered_df['organization_id'].isin(\n            org_data[org_data['City'] == city]['ID'])]\n    if province:\n        filtered_df = filtered_df[filtered_df['organization_id'].isin(\n            org_data[org_data['State'] == province]['ID'])]\n    if country:\n        filtered_df = filtered_df[filtered_df['organization_id'].isin(\n            org_data[org_data['Country'] == country]['ID'])]\n\n    # Create graphs\n    graphs = []\n    # Append each graph to the list\n    graphs.append(top_names(filtered_df))\n    graphs.append(top_names_per_species(filtered_df))\n    graphs.append(animals_per_species(filtered_df))\n    graphs.append(dogs_per_breed(filtered_df))\n    graphs.append(cats_per_breed(filtered_df))\n    return graphs \n\n@app.callback(\n    Output('graph-container', 'children'),\n    [Input('toggle-provincial', 'value'),\n     Input('city-dropdown', 'value'),\n     Input('state-dropdown', 'value'),\n     Input('country-dropdown', 'value')]\n)\ndef update_graph_container(toggle_value, city, province, country):\n    # Update graphs based on toggle value and selected city, province, and country\n    graphs = update_graphs(df, city, province, country)\n    # Create a div to contain all the graphs\n    graph_divs = [dcc.Graph(figure=graph) for graph in graphs]\n    return graph_divs \n\n\n@app.callback(\n    Output('output', 'children'),\n    [Input('dropdown', 'value')]\n)\ndef update_output(selected_country):\n    if selected_country:\n        # Here you can perform further operations based on the selected country\n        return f'You have selected country {selected_country}'\n    else:\n        return 'Please select a country'\n\n\n@app.callback(\n    Output('state-dropdown', 'options'),\n    [Input('country-dropdown', 'value')]\n)\ndef update_state_options(selected_country):\n    if selected_country:\n        # Filter DataFrame based on selected country\n        filtered_data = org_data[org_data['Country'] == selected_country]\n        # Get unique states for the selected country\n        unique_states = filtered_data['State'].unique()\n        # Generate options for state dropdown\n        state_options = [{'label': state, 'value': state}\n                         for state in unique_states]\n        return state_options\n    else:\n        return []\n\n\n@app.callback(\n    Output('city-dropdown', 'options'),\n    [Input('state-dropdown', 'value')]\n)\ndef update_city_options(selected_state):\n    if selected_state:\n        # Filter org_data based on selected state\n        filtered_data = org_data[org_data['State'] == selected_state]\n        # Get unique cities for the selected state\n        unique_cities = filtered_data['City'].unique()\n        # Generate options for city dropdown\n        city_options = [{'label': city, 'value': city}\n                        for city in unique_cities]\n        return city_options\n    else:\n        return []",
        "tags": [
            "python",
            "html",
            "web-applications",
            "visualization",
            "plotly-dash",
            "python",
            "html",
            "web-applications",
            "visualization",
            "plotly-dash"
        ],
        "answers": [
            "I am new to dash, and building an app to visualize some data. Here's my problem. In my app, I have 3 navbar tabs to visualize data. Each tab corresponds to the level at which you can view the data, going from National view, a state view, and then a city view. Each view has drop down menus that correspond with how you can filter the data. The city view has 3, for the country, state and city. The State view has 2, and the country view has 1. The value of one drop down menu, is supposed to be input for the other. Eg, you can pick the states of a chosen country.\nCurrently, only the city view will work, and I get errors with the other 2 views.\nThis is the error I'm getting with the provincial and country view.\n\"A nonexistent object was used in an Input of a Dash callback. The id of this object is city-dropdown and the property is value.\"\nBelow is the relevant code. I'm hoping somebody can help me diagnose the issue, or suggest a more optimal way to do this. I am new to dash, and figuring this all out for the first time.\n@app.callback(Output('toggle-switches-content', 'children'),\n              [Input('url', 'pathname')])\ndef update_toggle_switches_content(pathname):\n    # The not working state view \n    if pathname == \"/provincial\":\n        return html.Div([\n            daq.ToggleSwitch(id='toggle-provincial', label=\"Real Time | Historical\",\n                             style={'display': 'inline-block', 'margin-right': '10px'}),\n\n            html.Div([\n                dcc.Dropdown(\n                    id='country-dropdown',\n                    options=[{'label': country, 'value': country}\n                        for country in unique_countries],\n                    value=None,  # Default value\n                    placeholder=\"Select a country\",\n                    style={'display': 'inline-block', 'margin-right': '10px',\n                        'width': '200px', 'height': '40px'}\n                ),\n                dcc.Dropdown(\n                    id='state-dropdown',\n                    value=None,  # Default value\n                    placeholder=\"Select a state\",\n                    style={'display': 'inline-block', 'margin-right': '10px',\n                           'width': '200px', 'height': '40px'}\n                ),\n            ], style={'display': 'inline-block'}),\n            html.Div(id='output'),\n            html.Div(id='graph-container', style={'margin-top': '20px'}),\n\n        ])\n    # The working city view \n    elif pathname == '/city':\n        return html.Div([\n            daq.ToggleSwitch(\n                id='toggle-provincial',\n                label=\"Real Time | Historical\",\n                style={'display': 'inline-block', 'margin-right': '10px'}\n            ),\n\n            html.Div([\n                dcc.Dropdown(\n                    id='country-dropdown',\n                    options=[{'label': country, 'value': country}\n                             for country in unique_countries],\n                    value=None,\n                    placeholder=\"Select a country\",\n                    style={'display': 'inline-block', 'margin-right': '10px',\n                           'width': '200px', 'height': '40px'}\n                ),\n                dcc.Dropdown(\n                    id='state-dropdown',\n                    value=None,\n                    placeholder=\"Select a state\",\n                    style={'display': 'inline-block', 'margin-right': '10px',\n                           'width': '200px', 'height': '40px'}\n                ),\n                dcc.Dropdown(\n                    id='city-dropdown',  # Add the city-dropdown here\n                    value=None,\n                    placeholder=\"Select a city\",\n                    style={'display': 'inline-block', 'margin-right': '10px',\n                           'width': '200px', 'height': '40px'}\n                ),\n            ], style={'display': 'inline-block'}),\n            html.Div(id='output'),\n            html.Div(id='graph-container', style={'margin-top': '20px'}),\n\n        ])  \n        # The  not working country view \n        else:\n        return html.Div([\n            daq.ToggleSwitch(id='toggle-provincial', label=\"Real Time | Historical\",\n                             style={'display': 'inline-block', 'margin-right': '10px'}),\n\n            dcc.Dropdown(\n                id='country-dropdown',\n                options=[{'label': country, 'value': country}\n                        for country in unique_countries],\n                value=None,  # Default value\n                style={'display': 'inline-block', 'margin-right': '10px',\n                       'width': '200px', 'height': '40px'}\n            ),\n            html.Div(id='output'),\n            html.Div(id='graph-container', style={'margin-top': '20px'}),\n\n        ]) \n\n\n\nRelevant call back functions \n\n\ndef update_graphs(df, city=None, province=None, country=None):\n    # Filter the DataFrame based on selected city, province, and country\n    filtered_df = df.copy()\n    if city:\n        filtered_df = filtered_df[filtered_df['organization_id'].isin(\n            org_data[org_data['City'] == city]['ID'])]\n    if province:\n        filtered_df = filtered_df[filtered_df['organization_id'].isin(\n            org_data[org_data['State'] == province]['ID'])]\n    if country:\n        filtered_df = filtered_df[filtered_df['organization_id'].isin(\n            org_data[org_data['Country'] == country]['ID'])]\n\n    # Create graphs\n    graphs = []\n    # Append each graph to the list\n    graphs.append(top_names(filtered_df))\n    graphs.append(top_names_per_species(filtered_df))\n    graphs.append(animals_per_species(filtered_df))\n    graphs.append(dogs_per_breed(filtered_df))\n    graphs.append(cats_per_breed(filtered_df))\n    return graphs \n\n@app.callback(\n    Output('graph-container', 'children'),\n    [Input('toggle-provincial', 'value'),\n     Input('city-dropdown', 'value'),\n     Input('state-dropdown', 'value'),\n     Input('country-dropdown', 'value')]\n)\ndef update_graph_container(toggle_value, city, province, country):\n    # Update graphs based on toggle value and selected city, province, and country\n    graphs = update_graphs(df, city, province, country)\n    # Create a div to contain all the graphs\n    graph_divs = [dcc.Graph(figure=graph) for graph in graphs]\n    return graph_divs \n\n\n@app.callback(\n    Output('output', 'children'),\n    [Input('dropdown', 'value')]\n)\ndef update_output(selected_country):\n    if selected_country:\n        # Here you can perform further operations based on the selected country\n        return f'You have selected country {selected_country}'\n    else:\n        return 'Please select a country'\n\n\n@app.callback(\n    Output('state-dropdown', 'options'),\n    [Input('country-dropdown', 'value')]\n)\ndef update_state_options(selected_country):\n    if selected_country:\n        # Filter DataFrame based on selected country\n        filtered_data = org_data[org_data['Country'] == selected_country]\n        # Get unique states for the selected country\n        unique_states = filtered_data['State'].unique()\n        # Generate options for state dropdown\n        state_options = [{'label': state, 'value': state}\n                         for state in unique_states]\n        return state_options\n    else:\n        return []\n\n\n@app.callback(\n    Output('city-dropdown', 'options'),\n    [Input('state-dropdown', 'value')]\n)\ndef update_city_options(selected_state):\n    if selected_state:\n        # Filter org_data based on selected state\n        filtered_data = org_data[org_data['State'] == selected_state]\n        # Get unique cities for the selected state\n        unique_cities = filtered_data['City'].unique()\n        # Generate options for city dropdown\n        city_options = [{'label': city, 'value': city}\n                        for city in unique_cities]\n        return city_options\n    else:\n        return []"
        ]
    },
    {
        "question_title": "How to import/install \"iou3d_nms_cuda\" as a ROS2 module?\n\n\n\n        Ask Question",
        "question_body": "I have successfully trained and tested a pointpillars network on my own point cloud dataset using https://github.com/shangjie-li/pointpillars/tree/master. I modified demo_in_ros.py from that repository to apply the trained model for 3D object detection using ROS2 (Humble). I used https://answers.ros.org/question/367793/including-a-python-module-in-a-ros2-package/ and was able to install all python codes (located in different folders) as modules in ROS2 workspace (ros2_pointpillars) /ros2_pointpillars/install/lidar_object_detection/lib/python3.10/site-packages/lidar_object_detection. I need to use iou3d_nms_cuda which is located in /ops/iou3d_nms folder. How can I import/install it as a module in ROS2?\nI appreciate any help in advance.\n#setup.py\nfrom setuptools import setup\npackage_name = 'lidar_object_detection'\nsubmodules = ['lidar_object_detection.utils',\n               'lidar_object_detection.layers.vfe','lidar_object_detection.layers.map_to_bev','lidar_object_detection.layers.backbones_2d','lidar_object_detection.layers.dense_heads',\n               'lidar_object_detection.ops.iou3d_nms', 'lidar_object_detection.ops.roiaware_pool3d', 'lidar_object_detection.ops.iou3d_nms.src',\n               #'lidar_object_detection.ops.iou3d_nms_cuda',              \n               'lidar_object_detection.data', 'lidar_object_detection.data.processor', 'lidar_object_detection.data.kitti_object_eval_python',\n               'lidar_object_detection.data.kitti', 'lidar_object_detection.data.augmentor'\n               ]\n\n\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=[package_name] + submodules,\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    maintainer='usr',\n    maintainer_email='[email protected]',\n    description='Object detection',\n    license='Apache License 2.0',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n               'subscriber = lidar_object_detection.demo_in_ros:main',\n        ],\n    },\n)\n\n#demo_in_ros.py\nimport argparse\nimport glob\nfrom pathlib import Path\nimport time\nimport os\nimport sys\nimport math\nimport threading\nimport rclpy\nfrom std_msgs.msg import Header\nfrom sensor_msgs.msg import PointCloud2\nfrom visualization_msgs.msg import Marker, MarkerArray\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nimport torch\n\nfrom .ops.iou3d_nms import iou3d_nms_cuda\nfrom .ops.iou3d_nms import iou3d_nms_utils\nfrom .data import cfg, cfg_from_yaml_file\nfrom .data import KittiDataset\nfrom .pointpillar import build_network, load_data_to_gpu\nfrom .utils import common_utils, calibration_kitti\nfrom .utils import opencv_vis_utils\nfrom .utils import numpy_pc2\n\n#package.xml\n<?xml version=\"1.0\"?>\n<?xml-model href=\"http://download.ros.org/schema/package_format3.xsd\" schematypens=\"http://www.w3.org/2001/XMLSchema\"?>\n<package format=\"3\">\n  <name>lidar_object_detection</name>\n  <version>0.0.0</version>\n  <description>Object detection</description>\n  <maintainer email=\"[email protected]\">usr</maintainer>\n  <license>Apache License 2.0</license>\n  \n  <exec_depend>rclpy</exec_depend>\n  <exec_depend>std_msgs</exec_depend>\n  <exec_depend>sensor_msgs</exec_depend>\n  <exec_depend>visualization_msgs</exec_depend>\n\n  <test_depend>ament_copyright</test_depend>\n  <test_depend>ament_flake8</test_depend>\n  <test_depend>ament_pep257</test_depend>\n  <test_depend>python3-pytest</test_depend>\n\n  <export>\n    <build_type>ament_python</build_type>\n  </export>\n</package>",
        "tags": [
            "python",
            "cuda",
            "ros2",
            "python",
            "cuda",
            "ros2"
        ],
        "answers": [
            "I have successfully trained and tested a pointpillars network on my own point cloud dataset using https://github.com/shangjie-li/pointpillars/tree/master. I modified demo_in_ros.py from that repository to apply the trained model for 3D object detection using ROS2 (Humble). I used https://answers.ros.org/question/367793/including-a-python-module-in-a-ros2-package/ and was able to install all python codes (located in different folders) as modules in ROS2 workspace (ros2_pointpillars) /ros2_pointpillars/install/lidar_object_detection/lib/python3.10/site-packages/lidar_object_detection. I need to use iou3d_nms_cuda which is located in /ops/iou3d_nms folder. How can I import/install it as a module in ROS2?\nI appreciate any help in advance.\n#setup.py\nfrom setuptools import setup\npackage_name = 'lidar_object_detection'\nsubmodules = ['lidar_object_detection.utils',\n               'lidar_object_detection.layers.vfe','lidar_object_detection.layers.map_to_bev','lidar_object_detection.layers.backbones_2d','lidar_object_detection.layers.dense_heads',\n               'lidar_object_detection.ops.iou3d_nms', 'lidar_object_detection.ops.roiaware_pool3d', 'lidar_object_detection.ops.iou3d_nms.src',\n               #'lidar_object_detection.ops.iou3d_nms_cuda',              \n               'lidar_object_detection.data', 'lidar_object_detection.data.processor', 'lidar_object_detection.data.kitti_object_eval_python',\n               'lidar_object_detection.data.kitti', 'lidar_object_detection.data.augmentor'\n               ]\n\n\nsetup(\n    name=package_name,\n    version='0.0.0',\n    packages=[package_name] + submodules,\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    maintainer='usr',\n    maintainer_email='[email protected]',\n    description='Object detection',\n    license='Apache License 2.0',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n               'subscriber = lidar_object_detection.demo_in_ros:main',\n        ],\n    },\n)\n\n#demo_in_ros.py\nimport argparse\nimport glob\nfrom pathlib import Path\nimport time\nimport os\nimport sys\nimport math\nimport threading\nimport rclpy\nfrom std_msgs.msg import Header\nfrom sensor_msgs.msg import PointCloud2\nfrom visualization_msgs.msg import Marker, MarkerArray\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nimport torch\n\nfrom .ops.iou3d_nms import iou3d_nms_cuda\nfrom .ops.iou3d_nms import iou3d_nms_utils\nfrom .data import cfg, cfg_from_yaml_file\nfrom .data import KittiDataset\nfrom .pointpillar import build_network, load_data_to_gpu\nfrom .utils import common_utils, calibration_kitti\nfrom .utils import opencv_vis_utils\nfrom .utils import numpy_pc2\n\n#package.xml\n<?xml version=\"1.0\"?>\n<?xml-model href=\"http://download.ros.org/schema/package_format3.xsd\" schematypens=\"http://www.w3.org/2001/XMLSchema\"?>\n<package format=\"3\">\n  <name>lidar_object_detection</name>\n  <version>0.0.0</version>\n  <description>Object detection</description>\n  <maintainer email=\"[email protected]\">usr</maintainer>\n  <license>Apache License 2.0</license>\n  \n  <exec_depend>rclpy</exec_depend>\n  <exec_depend>std_msgs</exec_depend>\n  <exec_depend>sensor_msgs</exec_depend>\n  <exec_depend>visualization_msgs</exec_depend>\n\n  <test_depend>ament_copyright</test_depend>\n  <test_depend>ament_flake8</test_depend>\n  <test_depend>ament_pep257</test_depend>\n  <test_depend>python3-pytest</test_depend>\n\n  <export>\n    <build_type>ament_python</build_type>\n  </export>\n</package>"
        ]
    },
    {
        "question_title": "Remove Child From CSS Grid\n\n\n\n        Ask Question",
        "question_body": "I have a form that is set up as a css grid, but I would like the submit button to always be at the bottom-right of the form.\nI have seen some examples of how to force a child onto a new row, and I'm currently using that code, but it always puts the button at the bottom-left.\nI've also toyed around with grid-column-end: -1, and that works for some widths, but it creates extra grids as the screen gets wider.\nHTML:\n<form id=\"sowingform\">\n    <fieldset>\n        <legend>Personal Information</legend>\n        <label for=\"firstname\">First Name</label>\n        <input type=\"text\" id=\"firstname\">\n        <label for=\"lastname\">Last Name</label>\n        <input type=\"text\" id=\"lastname\">\n        <label for=\"phone\">Phone Number</label>\n        <input type=\"text\" id=\"phone\">\n        <label for=\"email\">E-Mail Address</label>\n        <input type=\"text\" id=\"email\">\n    </fieldset>\n    <fieldset>\n        <legend>Mailing Address</legend>\n        <label for=\"address\">Street</label>\n        <input type=\"text\" id=\"address\">\n        <label for=\"city\">City</label>\n        <input type=\"text\" id=\"city\">\n        <label for=\"state\">State</label>\n        <input type=\"text\" id=\"state\">\n        <label for=\"zip\">Zip Code</label>\n        <input type=\"text\" id=\"zip\">\n    </fieldset>\n    <fieldset>\n        <legend>Credit Card Information</legend>\n        <label for=\"ccnumber\">Credit Card Number</label>\n        <input type=\"text\" id=\"ccnumber\">\n        <label for=\"expiration\">Expiration Date</label>\n        <input type=\"text\" id=\"expiration\">\n        <label for=\"code\">CVV</label>\n        <input type=\"text\" id=\"code\">\n    </fieldset>\n    <input type=\"submit\" value=\"Submit\">\n</form>\n\nCSS:\n#sowing form {\n    display: grid;\n    grid-template-columns: repeat(auto-fit, minmax(175px, 1fr));\n    gap: 1rem;\n}\n#sowing fieldset {\n    border: 1px solid white;\n}\n#sowing legend {\n    margin-left: 0.25rem;\n    padding: 0.5rem;\n    border: 1px solid white;\n}\n#sowing label,\n#sowing input {\n    display: block;\n    width: calc(100% - 0.5rem);\n}\n#sowing label {\n    margin-bottom: 0.25rem;\n}\n#sowing input {\n    margin-bottom: 1rem;\n}\n#sowing input[type=\"submit\"] {\n    grid-column-start: 1;\n    place-self: end;\n    width: auto;\n    padding: 0.25rem 0.5rem;\n}\n\nThe form is display: grid, each fieldset is at least 175px and at most 100%, and it puts them beside each other as many times as the window width allows.  I would just like the Submit button to be attached to the bottom-right, regardless of the number of columns.",
        "tags": [
            "html",
            "css",
            "css-grid",
            "html",
            "css",
            "css-grid"
        ],
        "answers": [
            "I have a form that is set up as a css grid, but I would like the submit button to always be at the bottom-right of the form.\nI have seen some examples of how to force a child onto a new row, and I'm currently using that code, but it always puts the button at the bottom-left.\nI've also toyed around with grid-column-end: -1, and that works for some widths, but it creates extra grids as the screen gets wider.\nHTML:\n<form id=\"sowingform\">\n    <fieldset>\n        <legend>Personal Information</legend>\n        <label for=\"firstname\">First Name</label>\n        <input type=\"text\" id=\"firstname\">\n        <label for=\"lastname\">Last Name</label>\n        <input type=\"text\" id=\"lastname\">\n        <label for=\"phone\">Phone Number</label>\n        <input type=\"text\" id=\"phone\">\n        <label for=\"email\">E-Mail Address</label>\n        <input type=\"text\" id=\"email\">\n    </fieldset>\n    <fieldset>\n        <legend>Mailing Address</legend>\n        <label for=\"address\">Street</label>\n        <input type=\"text\" id=\"address\">\n        <label for=\"city\">City</label>\n        <input type=\"text\" id=\"city\">\n        <label for=\"state\">State</label>\n        <input type=\"text\" id=\"state\">\n        <label for=\"zip\">Zip Code</label>\n        <input type=\"text\" id=\"zip\">\n    </fieldset>\n    <fieldset>\n        <legend>Credit Card Information</legend>\n        <label for=\"ccnumber\">Credit Card Number</label>\n        <input type=\"text\" id=\"ccnumber\">\n        <label for=\"expiration\">Expiration Date</label>\n        <input type=\"text\" id=\"expiration\">\n        <label for=\"code\">CVV</label>\n        <input type=\"text\" id=\"code\">\n    </fieldset>\n    <input type=\"submit\" value=\"Submit\">\n</form>\n\nCSS:\n#sowing form {\n    display: grid;\n    grid-template-columns: repeat(auto-fit, minmax(175px, 1fr));\n    gap: 1rem;\n}\n#sowing fieldset {\n    border: 1px solid white;\n}\n#sowing legend {\n    margin-left: 0.25rem;\n    padding: 0.5rem;\n    border: 1px solid white;\n}\n#sowing label,\n#sowing input {\n    display: block;\n    width: calc(100% - 0.5rem);\n}\n#sowing label {\n    margin-bottom: 0.25rem;\n}\n#sowing input {\n    margin-bottom: 1rem;\n}\n#sowing input[type=\"submit\"] {\n    grid-column-start: 1;\n    place-self: end;\n    width: auto;\n    padding: 0.25rem 0.5rem;\n}\n\nThe form is display: grid, each fieldset is at least 175px and at most 100%, and it puts them beside each other as many times as the window width allows.  I would just like the Submit button to be attached to the bottom-right, regardless of the number of columns."
        ]
    },
    {
        "question_title": "Nginx truncates large files when used as a proxy server. How it is fix?\n\n\n\n        Ask Question",
        "question_body": "I'm writing a distributed service where there are several servers. Separate servers are responsible for various functions of the service: request processing, frontend, CDN, etc.\nAnd one server works as an entry point, the domain refers to it and it distributes based on the uri to which server to redirect the request.\nThe problem is that some requests are dropped. If I send a file over 1MB, it may be cut off. Server Tuning\nevents {\n        worker_connections 768;\n        multi_accept on;\n}\n\nhttp {\n        client_max_body_size 500M;\n        sendfile on;\n        tcp_nopush on;\n        server_names_hash_bucket_size 2048;\n        include /etc/nginx/mime.types;\n        default_type application/octet-stream;\n        ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE\n        ssl_prefer_server_ciphers on;\n        access_log /var/log/nginx/access.log;\n        gzip off;\n        include /etc/nginx/conf.d/*.conf;\n        include /etc/nginx/sites-enabled/*;\n        server {\n                server_name tydi.ru www.tydi.ru;\n                location / {\n                        proxy_pass http://217.197.116.112:83;\n                 }\n\n                listen 443 ssl; # managed by Certbot\n                ssl_certificate /etc/letsencrypt/live/tydi.ru/fullchain.pem; # managed by Certbot\n                ssl_certificate_key /etc/letsencrypt/live/tydi.ru/privkey.pem; # managed by Certbot\n                include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n                ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n        }\n        server {\n                return 301 https://$host$request_uri;\n                listen      80;\n                server_name tydi.ru www.tydi.ru;\n        }\n}",
        "tags": [
            "nginx",
            "nginx"
        ],
        "answers": [
            "I'm writing a distributed service where there are several servers. Separate servers are responsible for various functions of the service: request processing, frontend, CDN, etc.\nAnd one server works as an entry point, the domain refers to it and it distributes based on the uri to which server to redirect the request.\nThe problem is that some requests are dropped. If I send a file over 1MB, it may be cut off. Server Tuning\nevents {\n        worker_connections 768;\n        multi_accept on;\n}\n\nhttp {\n        client_max_body_size 500M;\n        sendfile on;\n        tcp_nopush on;\n        server_names_hash_bucket_size 2048;\n        include /etc/nginx/mime.types;\n        default_type application/octet-stream;\n        ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE\n        ssl_prefer_server_ciphers on;\n        access_log /var/log/nginx/access.log;\n        gzip off;\n        include /etc/nginx/conf.d/*.conf;\n        include /etc/nginx/sites-enabled/*;\n        server {\n                server_name tydi.ru www.tydi.ru;\n                location / {\n                        proxy_pass http://217.197.116.112:83;\n                 }\n\n                listen 443 ssl; # managed by Certbot\n                ssl_certificate /etc/letsencrypt/live/tydi.ru/fullchain.pem; # managed by Certbot\n                ssl_certificate_key /etc/letsencrypt/live/tydi.ru/privkey.pem; # managed by Certbot\n                include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n                ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n        }\n        server {\n                return 301 https://$host$request_uri;\n                listen      80;\n                server_name tydi.ru www.tydi.ru;\n        }\n}"
        ]
    },
    {
        "question_title": "restore influxdb database without backup\n\n\n\n        Ask Question",
        "question_body": "I had an influxdb (v1.8) server running properly for 2,5 years on a raspberry pi 4, with an SSD.\nUnfortunately, after a power cut my raspberry do not start anymore.\nNow, I have inserted a pi image on a SD Card, booted from it, and now I can see the 2 partitions of my former SSD installation, boot and rootfs.\nSo, I guess the issue comes from a corrupted boot partition,as the SSD seems working fine, mounted on ~/media/boot and ~/media/rootfs\nAnyway, I have installed influxdb on the SD card, and I am searching for a way to connect it to my datas on the SSD. Is it possible?\nI see influxdb installation under ~/media/rootfs/var/lib/influxdb/* on my SSD. As I guess, this should contain my former database, or am I wrong?\nI have tried to tweak /etc/influxdb/influxdb.conf\n[meta] dir, [data] dir, wal-dir, changing pathes to point to the SSD, but no way, influx service does not start anymore.\nSo, where stand my datas, and how could I connect to/backup them ?\nThanks for any help\nClaude",
        "tags": [
            "influxdb",
            "influxdb"
        ],
        "answers": [
            "I had an influxdb (v1.8) server running properly for 2,5 years on a raspberry pi 4, with an SSD.\nUnfortunately, after a power cut my raspberry do not start anymore.\nNow, I have inserted a pi image on a SD Card, booted from it, and now I can see the 2 partitions of my former SSD installation, boot and rootfs.\nSo, I guess the issue comes from a corrupted boot partition,as the SSD seems working fine, mounted on ~/media/boot and ~/media/rootfs\nAnyway, I have installed influxdb on the SD card, and I am searching for a way to connect it to my datas on the SSD. Is it possible?\nI see influxdb installation under ~/media/rootfs/var/lib/influxdb/* on my SSD. As I guess, this should contain my former database, or am I wrong?\nI have tried to tweak /etc/influxdb/influxdb.conf\n[meta] dir, [data] dir, wal-dir, changing pathes to point to the SSD, but no way, influx service does not start anymore.\nSo, where stand my datas, and how could I connect to/backup them ?\nThanks for any help\nClaude"
        ]
    },
    {
        "question_title": "What is the difference between a HashiCorp Vault lease and token accessor?\n\n\n\n        Ask Question",
        "question_body": "In HashiCorp Vault, when you create a service token a lease is created and you get a token accessor. The lease ID is described as:\n\nThis is the ID used with commands such as vault lease renew and vault lease revoke to manage the lease of the secret.\n\nThe vault lease command doesn't work with service tokens, but service tokens also get leases, so the concept is present.\nToken accessors are documented as having a limited set of actions, where the ability to renew and revoke a token is two of four such actions.\nSo from my perspective leases and accessors seem to have some overlapping functionality. What is the difference?",
        "tags": [
            "hashicorp-vault",
            "hashicorp-vault"
        ],
        "answers": [
            "In HashiCorp Vault, when you create a service token a lease is created and you get a token accessor. The lease ID is described as:\n\nThis is the ID used with commands such as vault lease renew and vault lease revoke to manage the lease of the secret.\n\nThe vault lease command doesn't work with service tokens, but service tokens also get leases, so the concept is present.\nToken accessors are documented as having a limited set of actions, where the ability to renew and revoke a token is two of four such actions.\nSo from my perspective leases and accessors seem to have some overlapping functionality. What is the difference?"
        ]
    },
    {
        "question_title": "Search a dataframe of paragraphs against a dataframe of substrings and return the substrings and the paragraph they matched against\n\n\n\n        Ask Question",
        "question_body": "I am searching through a web page against a list of names in a data frame. If a name appears in a paragraph I want to know which paragraph so I can parse certain parts of that paragraph and then associate it with the name.\nI have two data frames:\ndfrule which is made up of 'Paragraphs' and 'Ids' and eldf which is made up of 'Names' and 'Ids'\nSo far I have:\nsubstring_matches = eldf['name'].apply(lambda s1: dfrule['Paragraphs'].apply(lambda s2: s1 in s2).any()\nmatchdf = eldf[substring_matches]\n\nThis gives me every name on the list that matched against any paragraph but not the Id of which paragraph it matched against. How would I be able to associate it with the paragraph id?",
        "tags": [
            "python",
            "pandas",
            "python",
            "pandas"
        ],
        "answers": [
            "I am searching through a web page against a list of names in a data frame. If a name appears in a paragraph I want to know which paragraph so I can parse certain parts of that paragraph and then associate it with the name.\nI have two data frames:\ndfrule which is made up of 'Paragraphs' and 'Ids' and eldf which is made up of 'Names' and 'Ids'\nSo far I have:\nsubstring_matches = eldf['name'].apply(lambda s1: dfrule['Paragraphs'].apply(lambda s2: s1 in s2).any()\nmatchdf = eldf[substring_matches]\n\nThis gives me every name on the list that matched against any paragraph but not the Id of which paragraph it matched against. How would I be able to associate it with the paragraph id?"
        ]
    },
    {
        "question_title": "SSH_MSG_DISCONNECT: 1 ssh disconnect host not allowed to connect\n\n\n\n        Ask Question",
        "question_body": "I'm upgrading my SFTP client library from com.jcraft.jsch 0.1.55 to com.github.mwiede.jsch 0.2.17 to utilize OpenSSH keys.\nMy previous code using com.jcraft.jsch 0.1.55 was working fine by providing the \"RSA PRIVATE KEY\". (I understand that SFTP servers do not share their private key). But I was able to connect like that. while it's now failing.\n  private void connectAndDo(\n      CitySftpConfigurationDTO sftpConfiguration, Consumer<ChannelSftp> action)\n      throws SftpConnectionException {\n    try {\n      retryTemplate.execute(\n          retryContext -> {\n            try {\n               Path tempFile = Files.createTempFile(\"private_sftp_key\", \"\");\n               Files.write(tempFile, sftpConfiguration.getPrivateKey().getBytes());\n               jsch.addIdentity(tempFile.toString());\n               Files.deleteIfExists(tempFile);\n            } catch (IOException e) {\n                throw new ShouldNotHappenException(\"Unable to create file for private key\");\n            }\n            Session session =\n                jsch.getSession(\n                    sftpConfiguration.getUsername(),\n                    sftpConfiguration.getHost(),\n                    sftpConfiguration.getPort());\n            if (!proxyHost.equals(\"\") && proxyPort != 0) {\n              session.setProxy(new ProxyHTTP(proxyHost, proxyPort));\n            }\n            session.setConfig(\"StrictHostKeyChecking\", \"no\");\n\n            /* added for com.github.mwiede.jsch 0.2.17 \n            session.setConfig(\"server_host_key\", \n                session.getConfig(\"server_host_key\") + \",ssh-rsa,ssh-dss\");\n            session.setConfig(\"PubkeyAcceptedAlgorithms\",\n                session.getConfig(\"PubkeyAcceptedAlgorithms\") + \",ssh-rsa,ssh-dss\");\n            */ \n\n            try {\n              session.connect();\n              Channel channel = session.openChannel(\"sftp\");\n              ChannelSftp channelSftp = (ChannelSftp) channel;\n              try {\n                channelSftp.connect();\n                action.accept(channelSftp);\n              } finally {\n                channelSftp.disconnect();\n              }\n            } finally {\n              session.disconnect();\n            }\n            return null;\n          });\n    } catch (JSchException e) {\n      throw new SftpConnectionException(CONNECTION_ERROR_MESSAGE, e);\n    }\n  }\n\nthe error code:\nCaused by: com.jcraft.jsch.JSchSessionDisconnectException: SSH_MSG_DISCONNECT: 1 ssh disconnect host not allowed to connect \n    at com.jcraft.jsch.Session.read(Session.java:1316)\n    at com.jcraft.jsch.UserAuthPublicKey._start(UserAuthPublicKey.java:325)\n    at com.jcraft.jsch.UserAuthPublicKey.start(UserAuthPublicKey.java:119)\n    at com.jcraft.jsch.Session.connect(Session.java:479)\n    at com.jcraft.jsch.Session.connect(Session.java:198)\n\nI'm expecting to use the second version with the same code",
        "tags": [
            "java",
            "spring-boot",
            "sftp",
            "jsch",
            "java",
            "spring-boot",
            "sftp",
            "jsch"
        ],
        "answers": [
            "I'm upgrading my SFTP client library from com.jcraft.jsch 0.1.55 to com.github.mwiede.jsch 0.2.17 to utilize OpenSSH keys.\nMy previous code using com.jcraft.jsch 0.1.55 was working fine by providing the \"RSA PRIVATE KEY\". (I understand that SFTP servers do not share their private key). But I was able to connect like that. while it's now failing.\n  private void connectAndDo(\n      CitySftpConfigurationDTO sftpConfiguration, Consumer<ChannelSftp> action)\n      throws SftpConnectionException {\n    try {\n      retryTemplate.execute(\n          retryContext -> {\n            try {\n               Path tempFile = Files.createTempFile(\"private_sftp_key\", \"\");\n               Files.write(tempFile, sftpConfiguration.getPrivateKey().getBytes());\n               jsch.addIdentity(tempFile.toString());\n               Files.deleteIfExists(tempFile);\n            } catch (IOException e) {\n                throw new ShouldNotHappenException(\"Unable to create file for private key\");\n            }\n            Session session =\n                jsch.getSession(\n                    sftpConfiguration.getUsername(),\n                    sftpConfiguration.getHost(),\n                    sftpConfiguration.getPort());\n            if (!proxyHost.equals(\"\") && proxyPort != 0) {\n              session.setProxy(new ProxyHTTP(proxyHost, proxyPort));\n            }\n            session.setConfig(\"StrictHostKeyChecking\", \"no\");\n\n            /* added for com.github.mwiede.jsch 0.2.17 \n            session.setConfig(\"server_host_key\", \n                session.getConfig(\"server_host_key\") + \",ssh-rsa,ssh-dss\");\n            session.setConfig(\"PubkeyAcceptedAlgorithms\",\n                session.getConfig(\"PubkeyAcceptedAlgorithms\") + \",ssh-rsa,ssh-dss\");\n            */ \n\n            try {\n              session.connect();\n              Channel channel = session.openChannel(\"sftp\");\n              ChannelSftp channelSftp = (ChannelSftp) channel;\n              try {\n                channelSftp.connect();\n                action.accept(channelSftp);\n              } finally {\n                channelSftp.disconnect();\n              }\n            } finally {\n              session.disconnect();\n            }\n            return null;\n          });\n    } catch (JSchException e) {\n      throw new SftpConnectionException(CONNECTION_ERROR_MESSAGE, e);\n    }\n  }\n\nthe error code:\nCaused by: com.jcraft.jsch.JSchSessionDisconnectException: SSH_MSG_DISCONNECT: 1 ssh disconnect host not allowed to connect \n    at com.jcraft.jsch.Session.read(Session.java:1316)\n    at com.jcraft.jsch.UserAuthPublicKey._start(UserAuthPublicKey.java:325)\n    at com.jcraft.jsch.UserAuthPublicKey.start(UserAuthPublicKey.java:119)\n    at com.jcraft.jsch.Session.connect(Session.java:479)\n    at com.jcraft.jsch.Session.connect(Session.java:198)\n\nI'm expecting to use the second version with the same code"
        ]
    }
]